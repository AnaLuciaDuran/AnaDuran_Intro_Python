{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands On Bayesian Statistics with Python, PyMC3 & ArviZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think Bayes’ theorem is counter-intuitive and Bayesian statistics, which builds upon Baye’s theorem, can be very hard to understand. I am with you.\n",
    "\n",
    "There are countless reasons why we should learn Bayesian statistics, in particular, Bayesian statistics is emerging as a powerful framework to express and understand next-generation deep neural networks.\n",
    "\n",
    "I believe that for the things we have to learn before we can do them, we learn by doing them. And nothing in life is so hard that we can’t make it easier by the way we take it.\n",
    "\n",
    "So, this is my way of making it easier: Rather than too much of theories or terminologies at the beginning, let’s focus on the mechanics of Bayesian analysis, in particular, how to do Bayesian analysis and visualization with PyMC3 & ArviZ. Prior to memorizing the endless terminologies, we will code the solutions and visualize the results, and using the terminologies and theories to explain the models along the way.\n",
    "\n",
    "PyMC3 is a Python library for probabilistic programming with a very simple and intuitive syntax. ArviZ, a Python library that works hand-in-hand with PyMC3 and can help us interpret and visualize posterior distributions.\n",
    "\n",
    "And we will apply Bayesian methods to a practical problem, to show an end-to-end Bayesian analysis that move from framing the question to building models to eliciting prior probabilities to implementing in Python the final posterior distribution.\n",
    "Before we start, let’s get some basic intuitions out of the way:\n",
    "\n",
    "Bayesian models are also known as probabilistic models because they are built using probabilities. And Bayesian’s use probabilities as a tool to quantify uncertainty. Therefore, the answers we get are distributions not point estimates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Approach Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Establish a belief about the data, including Prior and Likelihood functions.\n",
    "    \n",
    "Step 2, Use the data and probability, in accordance with our belief of the data, to update our model, check that our model agrees with the original data.\n",
    "\n",
    "Step 3, Update our view of the data based on our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am interested in using machine learning for price optimization, I decide to apply Bayesian methods to a Spanish High Speed Rail tickets pricing data set that can be found here. Appreciate The Gurus team for scraping the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymc3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2e5c536b7c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymc3'"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'theano'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-964d5885b44d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'theano'"
     ]
    }
   ],
   "source": [
    "from theano import shared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e8fcc0d2b127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running on PyMC3 v{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "print('Running on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insert_date</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>train_type</th>\n",
       "      <th>price</th>\n",
       "      <th>train_class</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420104</th>\n",
       "      <td>2019-04-22 08:00:25</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>SEVILLA</td>\n",
       "      <td>2019-04-28 08:30:00</td>\n",
       "      <td>2019-04-28 11:14:00</td>\n",
       "      <td>ALVIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turista</td>\n",
       "      <td>Flexible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431888</th>\n",
       "      <td>2019-04-22 10:03:24</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>VALENCIA</td>\n",
       "      <td>2019-05-20 06:45:00</td>\n",
       "      <td>2019-05-20 08:38:00</td>\n",
       "      <td>AVE</td>\n",
       "      <td>21.95</td>\n",
       "      <td>Turista</td>\n",
       "      <td>Promo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791293</th>\n",
       "      <td>2019-04-25 19:19:46</td>\n",
       "      <td>MADRID</td>\n",
       "      <td>SEVILLA</td>\n",
       "      <td>2019-05-29 06:20:00</td>\n",
       "      <td>2019-05-29 09:16:00</td>\n",
       "      <td>AV City</td>\n",
       "      <td>38.55</td>\n",
       "      <td>Turista</td>\n",
       "      <td>Promo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                insert_date  origin destination           start_date  \\\n",
       "420104  2019-04-22 08:00:25  MADRID     SEVILLA  2019-04-28 08:30:00   \n",
       "431888  2019-04-22 10:03:24  MADRID    VALENCIA  2019-05-20 06:45:00   \n",
       "791293  2019-04-25 19:19:46  MADRID     SEVILLA  2019-05-29 06:20:00   \n",
       "\n",
       "                   end_date train_type  price train_class      fare  \n",
       "420104  2019-04-28 11:14:00      ALVIA    NaN     Turista  Flexible  \n",
       "431888  2019-05-20 08:38:00        AVE  21.95     Turista     Promo  \n",
       "791293  2019-05-29 09:16:00    AV City  38.55     Turista     Promo  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('renfe.csv')\n",
    "data.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "data = data.sample(frac=0.01, random_state=99)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insert_date    0.000000\n",
       "origin         0.000000\n",
       "destination    0.000000\n",
       "start_date     0.000000\n",
       "end_date       0.000000\n",
       "train_type     0.000000\n",
       "price          0.119467\n",
       "train_class    0.003993\n",
       "fare           0.003993\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12% of values in price column are missing, I decide to fill them with the mean of the respective fare types. Also fill the other two categorical columns with the most common values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train_class'] = data['train_class'].fillna(data['train_class'].mode().iloc[0])\n",
    "data['fare'] = data['fare'].fillna(data['fare'].mode().iloc[0])\n",
    "data['price'] = data.groupby('fare').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-452d7a0c75ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_kde\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_kde(data['price'].values, rug=True)\n",
    "plt.yticks([0], alpha=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KDE plot of the rail ticket price shows a Gaussian-like distribution, except for about several dozens of data points that are far away from the mean.\n",
    "\n",
    "Let’s assume that a Gaussian distribution is a proper description of the rail ticket price. Since we do not know the mean or the standard deviation, we must set priors for both of them. Therefore, a reasonable model could be as follows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform Gaussian inferences on the ticket price data. Here’s some of the modelling choices that go into this.\n",
    "\n",
    "**We would instantiate the Models in PyMC3 like this:**\n",
    "\n",
    "Model specifications in PyMC3 are wrapped in a with-statement.\n",
    "\n",
    "**Choices of priors:**\n",
    "\n",
    "- μ, mean of a population. Normal distribution, very wide. I do not know the possible values of μ, I can set priors reflecting my ignorance. From experience I know that train ticket price can not be lower than 0 or higher than 300, so I set the boundaries of the uniform distribution to be 0 and 300. You may have different experience and set the different boundaries. That is totally fine. And if you have more reliable prior information than I do, please use it!.\n",
    "\n",
    "- σ, standard deviation of a population. Can only be positive, therefore use HalfNormal distribution. Again, very wide.\n",
    "\n",
    "Choices for ticket price likelihood function:\n",
    "\n",
    "- y is an observed variable representing the data that comes from a normal distribution with the parameters μ and σ.\n",
    "\n",
    "- Draw 1000 posterior samples using NUTS sampling.\n",
    "\n",
    "Using PyMC3, we can write the model as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7735e03669eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel_g\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mμ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'μ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mσ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHalfNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'σ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mμ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mσ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrace_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_g:\n",
    "    μ = pm.Uniform('μ', lower=0, upper=300)\n",
    "    σ = pm.HalfNormal('σ', sd=10)\n",
    "    y = pm.Normal('y', mu=μ, sd=σ, observed=data['price'].values)\n",
    "    trace_g = pm.sample(1000, tune=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y specifies the likelihood. This is the way in which we tell PyMC3 that we want to condition for the unknown on the knows (data).\n",
    "\n",
    "We plot the gaussian model trace. This runs on a Theano graph under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4693834c10df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_trace(trace_g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On the left, we have a KDE plot, — for each parameter value on the x-axis we get a probability on the y-axis that tells us how likely that parameter value is.\n",
    "\n",
    "\n",
    "- On the right, we get the individual sampled values at each step during the sampling. From the trace plot, we can visually get the plausible values from the posterior.\n",
    "\n",
    "\n",
    "- The above plot has one row for each parameter. For this model, the posterior is bi-dimensional, and so the above figure is showing the marginal distributions of each parameter.\n",
    "\n",
    "There are a couple of things to notice here:\n",
    "\n",
    "- Our sampling chains for the individual parameters (left) seem well converged and stationary (there are no large drifts or other odd patterns).\n",
    "\n",
    "- The maximum posterior estimate of each variable (the peak in the left side distributions) is very close to the true parameters.\n",
    "     \n",
    "We can plot a joint distributions of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2eb0712fefdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_joint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kde'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_last\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_joint(trace_g, kind='kde', fill_last=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don’t see any correlation between these two parameters. This means we probably do not have collinearity in the model. This is good.\n",
    "\n",
    "\n",
    "We can also have a detailed summary of the posterior distribution for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-99c413a82519>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.summary(trace_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the above summary visually by generating a plot with the mean and Highest Posterior Density (HPD) of a distribution, and to interpret and report the results of a Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d63f1982a57e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_posterior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_posterior(trace_g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unlike Frequentist inference, in Bayesian inference, we get the entire distribution of the values.\n",
    "\n",
    "- Every time ArviZ computes and reports a HPD, it will use, by default, a value of 94%.\n",
    "\n",
    "- Please note that HPD intervals are not the same as confidence intervals. \n",
    "\n",
    "- Here we can interpret as such that there is 94% probability the belief is between 63.8 euro and 64.4 euro for the mean ticket price.\n",
    "\n",
    "We can verify the convergence of the chains formally using the Gelman Rubin test. Values close to 1.0 mean convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0a1a30bf3fb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelman_rubin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "pm.gelman_rubin(trace_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c4acad0ade5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbfmi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbfmi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmax_gr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgr_stats\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgr_stats\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelman_rubin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergyplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BFMI = {}\\nGelman-Rubin = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbfmi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_gr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "bfmi = pm.bfmi(trace_g)\n",
    "max_gr = max(np.max(gr_stats) for gr_stats in pm.gelman_rubin(trace_g).values())\n",
    "(pm.energyplot(trace_g, legend=False, figsize=(6, 4)).set_title(\"BFMI = {}\\nGelman-Rubin = {}\".format(bfmi, max_gr)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has converged well and the Gelman-Rubin statistic looks fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Posterior predictive checks (PPCs) are a great way to validate a model. The idea is to generate data from the model using parameters from draws from the posterior.\n",
    "\n",
    "\n",
    "- Now that we have computed the posterior, we are going to illustrate how to use the simulation results to derive predictions.\n",
    "\n",
    "\n",
    "- The following function will randomly draw 1000 samples of parameters from the trace. Then, for each sample, it will draw 25798 random numbers from a normal distribution specified by the values of μ and σ in that sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cb70bb93162a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mppc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_posterior_predictive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mppc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace_g, samples=1000, model=model_g)\n",
    "np.asarray(ppc['y']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ppc contains 1000 generated data sets (containing 25798 samples each), each using a different parameter setting from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-461e883db1b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mppc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Posterior predictive of the mean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean(x)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Frequency'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ppc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist([y.mean() for y in ppc['y']], bins=19, alpha=0.5)\n",
    "ax.axvline(data.price.mean())\n",
    "ax.set(title='Posterior predictive of the mean', xlabel='mean(x)', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred mean is very close to the actual rail ticket price mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be interested in how price compare under different fare types. We are going to focus on estimating the effect size, that is, quantifying the difference between two fare categories. To compare fare categories, we are going to use the mean of each fare type. Because we are Bayesian, we will work to obtain a posterior distribution of the differences of means between fare categories.\n",
    "\n",
    "We create three variables:\n",
    "\n",
    "- The price variable, representing the ticket price.\n",
    "\n",
    "- The idx variable, a categorical dummy variable to encode the fare categories with numbers.\n",
    "\n",
    "- And finally the groups variable, with the number of fare categories (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = data['price'].values\n",
    "idx = pd.Categorical(data['fare'],\n",
    "                     categories=['Flexible', 'Promo', 'Promo +', 'Adulto ida', 'Mesa', 'Individual-Flexible']).codes\n",
    "groups = len(np.unique(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for the group comparison problem is almost the same as the previous model. the only difference is that μ and σ are going to be vectors instead of scalar variables. This means that for the priors, we pass a shape argument and for the likelihood, we properly index the means and sd variables using the idx variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as comparing_groups:\n",
    "    μ = pm.Normal('μ', mu=0, sd=10, shape=groups)\n",
    "    σ = pm.HalfNormal('σ', sd=10, shape=groups)\n",
    "\n",
    "    y = pm.Normal('y', mu=μ[idx], sd=σ[idx], observed=price)\n",
    "\n",
    "    trace_groups = pm.sample(5000, tune=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 6 groups (fare categories), its a little hard to plot trace plot for μ and σ for every group. So, we create a summary table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that there are significant differences between groups (i.e. fare categories) on the mean.\n",
    "\n",
    "To make it clearer, we plot the difference between each fare category without repeating the comparison.\n",
    "\n",
    "- Cohen’s d is an appropriate effect size for the comparison between two means. Cohen’s d introduces the variability of each group by using their standard deviations.\n",
    "\n",
    "- probability of superiority (ps) is defined as the probability that a data point taken at random from one group has a larger value than one taken at random from another group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stats.norm()\n",
    "\n",
    "_, ax = plt.subplots(5, 2, figsize=(20, 12), constrained_layout=True)\n",
    "\n",
    "comparisons = [(i, j) for i in range(6) for j in range(i+1, 6)]\n",
    "pos = [(k, l) for k in range(5) for l in (0, 1)]\n",
    "\n",
    "for (i, j), (k, l) in zip(comparisons, pos):\n",
    "    means_diff = trace_groups['μ'][:, i] - trace_groups['μ'][:, j]\n",
    "    d_cohen = (means_diff / np.sqrt((trace_groups['σ'][:, i]**2 + trace_groups['σ'][:, j]**2) / 2)).mean()\n",
    "    ps = dist.cdf(d_cohen/(2**0.5))\n",
    "    az.plot_posterior(means_diff, ref_val=0, ax=ax[k, l])\n",
    "    ax[k, l].set_title(f'$\\mu_{i}-\\mu_{j}$')\n",
    "    ax[k, l].plot(\n",
    "        0, label=f\"Cohen's d = {d_cohen:.2f}\\nProb sup = {ps:.2f}\", alpha=0)\n",
    "    ax[k, l].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the above plot tells us that none of the above comparison cases where the 94% HPD includes the reference value of zero. This means for all the examples, we can rule out a difference of zero. The average differences range of 6.1 euro to 63.5 euro are large enough that it can justify for customers to purchase tickets according to different fare categories.\n",
    "\n",
    "## Bayesian Hierarchical Linear Regression\n",
    "\n",
    "We want to build a model to estimate the rail ticket price of each train type, and, at the same time, estimate the price of all the train types. This type of model is known as a hierarchical model or multilevel model.\n",
    "\n",
    "- Encoding the categorical variable.\n",
    "\n",
    "- The idx variable, a categorical dummy variable to encode the train types with numbers.\n",
    "- And finally the groups variable, with the number of train types (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_fare(fare):\n",
    "    \n",
    "    if fare == 'Adulto ida':\n",
    "        return 1\n",
    "    elif fare == 'Promo +':\n",
    "        return 2\n",
    "    elif fare == 'Promo':\n",
    "        return 3\n",
    "    elif fare == 'Flexible':\n",
    "        return 4\n",
    "    elif fare == 'Individual-Flexible':\n",
    "        return 5\n",
    "    elif fare == 'Mesa':\n",
    "        return 6\n",
    "\n",
    "data['fare_encode'] = data['fare'].apply(lambda x: replace_fare(x))\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "data['train_type_encode']= label_encoder.fit_transform(data['train_type'])\n",
    "\n",
    "train_type_names = data.train_type.unique()\n",
    "train_type_idx = data.train_type_encode.values\n",
    "\n",
    "n_train_types = len(data.train_type.unique())\n",
    "\n",
    "data[['train_type', 'price', 'fare_encode']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant part of the data we will model looks as above. And we are interested in whether different train types affect the ticket price.\n",
    "\n",
    "## Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0424a7aa35e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhierarchical_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# global model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mα_μ_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'α_μ_tmp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mα_σ_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHalfNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'α_σ_tmp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mβ_μ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'β_μ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "with pm.Model() as hierarchical_model:\n",
    "    # global model parameters\n",
    "    α_μ_tmp = pm.Normal('α_μ_tmp', mu=0., sd=100)\n",
    "    α_σ_tmp = pm.HalfNormal('α_σ_tmp', 5.)\n",
    "    β_μ = pm.Normal('β_μ', mu=0., sd=100)\n",
    "    β_σ = pm.HalfNormal('β_σ', 5.)\n",
    "\n",
    "    # train type specific model parameters\n",
    "    α_tmp = pm.Normal('α_tmp', mu=α_μ_tmp, sd=α_σ_tmp, shape=n_train_types)  \n",
    "    # Intercept for each train type, distributed around train type mean \n",
    "    β = pm.Normal('β', mu=β_μ, sd=β_σ, shape=n_train_types)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy('eps', 5.)\n",
    "\n",
    "    fare_est = α_tmp[train_type_idx] + β[train_type_idx]*data.fare_encode.values\n",
    "\n",
    "    # Data likelihood\n",
    "    fare_like = pm.Normal('fare_like', mu=fare_est, sd=eps, observed=data.price)\n",
    "    \n",
    "with hierarchical_model:\n",
    "    hierarchical_trace = pm.sample(2000, tune=2000, target_accept=.9)\n",
    "    \n",
    "pm.traceplot(hierarchical_trace, var_names=['α_μ_tmp', 'β_μ', 'α_σ_tmp', 'β_σ', 'eps']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal posteriors in the left column are highly informative, “α_μ_tmp” tells us the group mean price levels, “β_μ” tells us that purchasing fare category “Promo +” increases price significantly compare to fare type “Adulto ida”, and purchasing fare category “Promo” increases price significantly compare to fare type “Promo +”, and so on (no mass under zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-860d644d066f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhierarchical_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'α_tmp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'α_tmp_dim_0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "pm.traceplot(hierarchical_trace, var_names=['α_tmp'], coords={'α_tmp_dim_0': range(5)});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among 16 train types, we may want to look at how 5 train types compare in terms of the ticket price. We can see by looking at the marginals for “α_tmp” that there is quite some difference in prices between train types; the different widths are related to how much confidence we have in each parameter estimate — the more measurements per train type, the higher our confidence will be.\n",
    "\n",
    "Having uncertainty quantification of some of our estimates is one of the powerful things about Bayesian modelling. We’ve got a Bayesian credible interval for the price of different train types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'az' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-89bde1b06cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhierarchical_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'α_tmp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'β'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'az' is not defined"
     ]
    }
   ],
   "source": [
    "az.plot_forest(hierarchical_trace, var_names=['α_tmp', 'β'], combined=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we may want to compute r squared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-be218a6f931a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mppc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_posterior_predictive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhierarchical_trace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhierarchical_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mppc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fare_like'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "ppc = pm.sample_posterior_predictive(hierarchical_trace, samples=2000, model=hierarchical_model)\n",
    "az.r2_score(data.price.values, ppc['fare_like'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this post is to learn, practice and explain Bayesian, not to produce the best possible results from the data set. Otherwise, we would have gone with XGBoost directly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
